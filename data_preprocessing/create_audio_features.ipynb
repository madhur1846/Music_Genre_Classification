{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the small directory\n",
    "SMALL_AUDIO_DIR = '../data/fma_small/'\n",
    "\n",
    "# function to get the paths to all the songs in the small dataset\n",
    "def audio_paths(AUDIO_DIR):\n",
    "    AUDIO_PATHS = []\n",
    "    # iterate through all the directories with songs in them\n",
    "    for path in [os.path.join('../data/fma_small/', p) \n",
    "                 for p in os.listdir('../data/fma_small/') \n",
    "                 if not (p.endswith('checksums') or p.endswith('.txt') or p.endswith('.DS_Store'))]:\n",
    "        # add all songs to the list\n",
    "        AUDIO_PATHS = AUDIO_PATHS + [os.path.join(path, track).replace('\\\\', '/') for track in os.listdir(path)]\n",
    "    \n",
    "    return AUDIO_PATHS\n",
    "\n",
    "# store all the small paths\n",
    "SMALL_PATHS = audio_paths(SMALL_AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load metadata\n",
    "# adapted from https://github.com/mdeff/fma/blob/master/utils.py\n",
    "def metadata_load(filepath):\n",
    "\n",
    "    filename = os.path.basename(filepath)\n",
    "\n",
    "    if 'features' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'echonest' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'genres' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0)\n",
    "\n",
    "    if 'tracks' in filename:\n",
    "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "\n",
    "        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
    "                   ('track', 'genres'), ('track', 'genres_all')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].map(ast.literal_eval)\n",
    "\n",
    "        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
    "                   ('album', 'date_created'), ('album', 'date_released'),\n",
    "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
    "                   ('artist', 'active_year_end')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = pd.to_datetime(tracks[column])\n",
    "\n",
    "        SUBSETS = ('small', 'medium', 'large')\n",
    "        try:\n",
    "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                    pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
    "        except ValueError:\n",
    "            # the categories and ordered arguments were removed in pandas 0.25\n",
    "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                     pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
    "\n",
    "        COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
    "                   ('album', 'type'), ('album', 'information'),\n",
    "                   ('artist', 'bio')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].astype('category')\n",
    "\n",
    "        return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get genre information for each track ID\n",
    "def track_genre_information(GENRE_PATH, TRACKS_PATH, FILE_PATHS, subset):\n",
    "    \"\"\"\n",
    "    GENRE_PATH (str): path to the csv with the genre metadata\n",
    "    TRACKS_PATH (str): path to the csv with the track metadata\n",
    "    FILE_PATHS (list): list of paths to the mp3 files\n",
    "    subset (str): the subset of the data desired\n",
    "    \"\"\"\n",
    "    # get the genre information\n",
    "    genres = pd.read_csv(GENRE_PATH)\n",
    "\n",
    "    # load metadata on all the tracks\n",
    "    tracks = metadata_load(TRACKS_PATH)\n",
    "\n",
    "    # focus on the specific subset tracks\n",
    "    subset_tracks = tracks[tracks['set', 'subset'] <= subset]\n",
    "\n",
    "    # extract track ID and genre information for each track\n",
    "    subset_tracks_genre = np.array([np.array(subset_tracks.index), \n",
    "                                  np.array(subset_tracks['track', 'genre_top'])]).T\n",
    "    \n",
    "    # extract track indices from the file paths\n",
    "    track_indices = []\n",
    "    for path in FILE_PATHS:\n",
    "        track_indices.append(path.split('/')[-1].split('.')[0].lstrip('0'))\n",
    "\n",
    "    # get the genre associated with each file path, thanks to the path ID\n",
    "    track_indices = pd.DataFrame({'file_path':FILE_PATHS,'track_id':np.array(track_indices).astype(int)})\n",
    "    tracks_genre_df = pd.DataFrame({'track_id': subset_tracks_genre[:,0], 'genre': subset_tracks_genre[:,1]})\n",
    "    track_genre_data = track_indices.merge(tracks_genre_df, how='left')\n",
    "    \n",
    "    # label classes with numbers\n",
    "    encoder = LabelEncoder()\n",
    "    track_genre_data['genre_nb'] = encoder.fit_transform(track_genre_data.genre)\n",
    "    \n",
    "    return track_genre_data\n",
    "\n",
    "# get genre information for all tracks from the small subset\n",
    "GENRE_PATH = '../data/fma_metadata/genres.csv'\n",
    "TRACKS_PATH = '../data/fma_metadata/tracks.csv'\n",
    "subset = 'small'\n",
    "\n",
    "small_tracks_genre = track_genre_information(GENRE_PATH, TRACKS_PATH, SMALL_PATHS, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split these paths and associated genres into training and test sets\n",
    "SMALL_AUDIO_TRAIN, SMALL_AUDIO_TEST = train_test_split(SMALL_PATHS, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfcc(file_path):\n",
    "    x, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "    mfccs = librosa.feature.mfcc(x, sr=sr)\n",
    "    return mfccs\n",
    "\n",
    "def compute_zcr(file_path):\n",
    "    x, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "    zcr = librosa.feature.zero_crossing_rate(x)\n",
    "    return zcr\n",
    "\n",
    "def compute_chroma_stft(file_path, hop_length = 512):\n",
    "    x, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "    stft = librosa.feature.chroma_stft(x, sr=sr, hop_length=hop_length)\n",
    "    return stft\n",
    "\n",
    "def compute_spectral_centroid(file_path):\n",
    "    x, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "    centroid = librosa.feature.spectral_centroid(x, sr=sr)\n",
    "    return centroid\n",
    "\n",
    "def compute_spectral_rolloff(file_path):\n",
    "    x, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "    rolloff = librosa.feature.spectral_rolloff(x+0.01, sr=sr)\n",
    "    return rolloff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Preprocesses data\n",
    "## ../data/fma_small/133/133297.mp3 - corrupt\n",
    "## ../data/fma_small/108/108925.mp3 - corrupt\n",
    "## ../data/fma_small/099/099134.mp3 - corrupt\n",
    "\n",
    "CONVERTED_TRAIN_PATH = '../data/pickle/train/'\n",
    "\n",
    "if not os.path.exists(CONVERTED_TRAIN_PATH):\n",
    "    os.mkdir(CONVERTED_TRAIN_PATH)\n",
    "    mfcc = defaultdict(np.array)\n",
    "    zcr = defaultdict(np.array)\n",
    "    chroma_stft = defaultdict(np.array)\n",
    "    spectral_centroid = defaultdict(np.array)\n",
    "    spectral_rolloff = defaultdict(np.array)\n",
    "    y = small_tracks_genre[small_tracks_genre.file_path.isin(SMALL_AUDIO_TRAIN)].genre.values\n",
    "    for small_path in SMALL_AUDIO_TRAIN:\n",
    "        try:\n",
    "            mfcc[small_path] = compute_mfcc(small_path)\n",
    "            zcr[small_path] = compute_zcr(small_path)\n",
    "            chroma_stft[small_path] = compute_chroma_stft(small_path)\n",
    "            spectral_centroid[small_path] = compute_spectral_centroid(small_path)\n",
    "            spectral_rolloff[small_path] = compute_spectral_rolloff(small_path)\n",
    "        except:\n",
    "            print(\"{} - corrupt\".format(small_path))\n",
    "    pickle.dump( mfcc, open( CONVERTED_TRAIN_PATH + \"mfcc.p\", \"wb\" ) )\n",
    "    pickle.dump( zcr, open( CONVERTED_TRAIN_PATH + \"zcr.p\", \"wb\" ) )\n",
    "    pickle.dump( chroma_stft, open( CONVERTED_TRAIN_PATH + \"chroma_stft.p\", \"wb\" ) )\n",
    "    pickle.dump( spectral_centroid, open( CONVERTED_TRAIN_PATH + \"spectral_centroid.p\", \"wb\" ) )\n",
    "    pickle.dump( spectral_rolloff, open( CONVERTED_TRAIN_PATH + \"spectral_rolloff.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVERTED_TEST_PATH = '../data/pickle/test/'\n",
    "\n",
    "if not os.path.exists(CONVERTED_TEST_PATH):\n",
    "    os.mkdir(CONVERTED_TEST_PATH)\n",
    "    mfcc_test = defaultdict(np.array)\n",
    "    zcr_test = defaultdict(np.array)\n",
    "    chroma_stft_test = defaultdict(np.array)\n",
    "    spectral_centroid_test = defaultdict(np.array)\n",
    "    spectral_rolloff_test = defaultdict(np.array)\n",
    "    y = small_tracks_genre[small_tracks_genre.file_path.isin(SMALL_AUDIO_TEST)].genre.values\n",
    "    for small_path in SMALL_AUDIO_TEST:\n",
    "        try:\n",
    "            mfcc_test[small_path] = compute_mfcc(small_path)\n",
    "            zcr_test[small_path] = compute_zcr(small_path)\n",
    "            chroma_stft_test[small_path] = compute_chroma_stft(small_path)\n",
    "            spectral_centroid_test[small_path] = compute_spectral_centroid(small_path)\n",
    "            spectral_rolloff_test[small_path] = compute_spectral_rolloff(small_path)\n",
    "        except:\n",
    "            print(\"{} - corrupt\".format(small_path))\n",
    "    pickle.dump( mfcc_test, open( CONVERTED_TEST_PATH + \"mfcc_test.p\", \"wb\" ) )\n",
    "    pickle.dump( zcr_test, open( CONVERTED_TEST_PATH + \"zcr_test.p\", \"wb\" ) )\n",
    "    pickle.dump( chroma_stft_test, open( CONVERTED_TEST_PATH + \"chroma_stft_test.p\", \"wb\" ) )\n",
    "    pickle.dump( spectral_centroid_test, open( CONVERTED_TEST_PATH + \"spectral_centroid_test.p\", \"wb\" ) )\n",
    "    pickle.dump( spectral_rolloff_test, open( CONVERTED_TEST_PATH + \"spectral_rolloff_test.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
